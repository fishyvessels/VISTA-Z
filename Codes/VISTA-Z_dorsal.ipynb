{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Import packages](#toc1_)    \n",
    "- [Set up working directory](#toc2_)    \n",
    "- [Vessel analysis - Dorsal images](#toc3_)    \n",
    "  - [Define parameters](#toc3_1_)    \n",
    "  - [Define functions](#toc3_2_)    \n",
    "  - [Run samples - Single channel](#toc3_3_)    \n",
    "  - [Run samples - Two or more channels](#toc3_4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Import packages](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import vessel_metrics as vm\n",
    "import czifile\n",
    "from aicspylibczi import CziFile\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.colors\n",
    "from matplotlib.pyplot import rc_context\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.stats import median_abs_deviation \n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import color\n",
    "from skimage.color import label2rgb\n",
    "from matplotlib.cm import get_cmap\n",
    "from skimage.morphology import remove_small_objects\n",
    "from aicsimageio import AICSImage, readers\n",
    "from scipy.spatial import distance\n",
    "from skimage.morphology import skeletonize\n",
    "import traceback\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Set up working directory](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the path to the working directory and the output folder where the 3D volumes will be saved.\n",
    "Define the name of the files to be processed.\n",
    "\"\"\"\n",
    "data_path = '/Users/irp/Library/CloudStorage/OneDrive-TheUniversityofNottingham/BBB project/Data/Embryo imaging/Vessel_metrics/03.06.2025/input_images/'\n",
    "output_path = '/Users/irp/Library/CloudStorage/OneDrive-TheUniversityofNottingham/BBB project/Data/Embryo imaging/Vessel_metrics/03.06.2025/output_images/trial'\n",
    "file_name = glob.glob(f'{data_path}*.*', recursive = True) # List of file names to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ensure the output directory exists and that files are read correctly.\n",
    "\"\"\"\n",
    "total_files = len(file_name)\n",
    "print(f\"Wolking forlder contains {total_files} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Vessel analysis - Dorsal images](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Define parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please README before running the following code ##\n",
    "\n",
    "## Parameters that the user should define before running VISTA-Z ROI analysis ##\n",
    "\n",
    "    # clahe = (int, int) # CLAHE parameters (clipLimit, tileGridSize)\n",
    "    # channel = int [0,1,2] # Channel number to be analysed per sample (only if multi-channel images) [0]: mCherry, [1]: EGFP, [2]: DAPI, etc.\n",
    "    # name_start = str # Starting string of the file names to be processed\n",
    "    # pdf_dpi = int # DPI for saving PDF figures\n",
    "    # min_vessel_size = int # Minimum vessel size (in pixels) to be thresholded for analysis\n",
    "    # Vessel segmentation parameters:\n",
    "        # seg_method = str # Vessel segmentation method: 'meijering', 'frangi', 'sato' or 'jerman'\n",
    "        # sigma1 = range(int, int, int) # Sigma range for vessel enhancement filter\n",
    "        # hole_size = int # Maximum hole size to be filled in the vessel mask\n",
    "        # ditzle_size = int # Maximum size of small objects to be removed from the vessel mask\n",
    "        # thresh = int # Threshold value to binarize the vessel enhanced image\n",
    "        # skel_method = str # Skeletonisation method: 'lee' or 'zhang'\n",
    "    # Branch_dist = int # Maximum distance (in pixels) to consider two vessel branches as connected\n",
    "    # MAD filtering threshold: Threshold for median absolute deviation (MAD) filtering of vessel metrics\n",
    "        # threshold_low = float \n",
    "        # threshold_high = float\n",
    "    # Normalisation of vessel metrics:\n",
    "        # window_size = 10 # 10 is to make an 100µm² area of 10x10. Transform into the low int value to create the scale for the density values\n",
    "        # scale = float # Scale factor to normalise vessel metrics (pixels per micron)\n",
    "    # output_name = str # Name of the output files to be saved (excel file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image pre-processing and ROI selection parameters\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
    "channel = 0 \n",
    "name_start = 'kdrlmCh_flk1EGFP'\n",
    "pdf_dpi = 300\n",
    "\n",
    "# Vessel segmentation parameters\n",
    "min_vessel_size = 500 # Note: Users are reccommended to set this parameter after initial analysis based on median(vessel_length) - std(vessel_length)\n",
    "seg_method = 'meijering'\n",
    "sigma1 = range(3, 8, 1)\n",
    "hole_size = 200\n",
    "ditzle_size = 50 # Note: Users are reccommended to set hole_size and ditzle_size based on the visualisation of the vessel mask after thresholding. Adjust these parameters to ensure that the vessel mask captures the vessels accurately while minimising noise and artefacts.\n",
    "thresh = 10 # Note: Users are reccommended to set this parameter based on the visualisation of the vessel enhanced image and the vessel mask after thresholding. Adjust this parameter to ensure that the vessel mask captures the vessels accurately while minimising noise and artefacts.\n",
    "skel_method = 'lee' \n",
    "\n",
    "#Branchpoint refinement parameters\n",
    "Branch_dist = 30 # Note: Users are reccommended to set this parameter based median(vessel_length)\n",
    "\n",
    "# MAD filtering threshold\n",
    "threshold_low = 1\n",
    "threshold_high = 3\n",
    "\n",
    "# Diameter calculation and vessel metrics normalisation parameters\n",
    "window_size = 10 # 10 is to make an 100µm² area of 10x10. Transform into the low int value to create the scale for the density values\n",
    "scale = 1.2044\n",
    "\n",
    "# Output file name\n",
    "output_name = \"VISTA-Z_dorsal_Results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Define functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_czi(file_path, file_name, output_path):\n",
    "    \"\"\"\n",
    "    Loads and processes a fluorescent image (.czi file) with a single channel, \n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Full path to the .czi file.\n",
    "        file_name (str): File name used to derive the sample ID.\n",
    "        output_path (str): Directory where output images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            image (ndarray): Raw image data after squeezing dimensions.\n",
    "            mip_image (ndarray): Normalized maximum-intensity projection (MIP) image in uint8.\n",
    "            gray_image (ndarray): Greyscale MIP image.\n",
    "            clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "            otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "            output_mip_path (str): Path for saving the MIP image.\n",
    "            output_mask_path (str): Path for saving the Otsu mask image.\n",
    "        Returns (None, None, None, None) if processing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sampleID = file_name.split('_MaxInt')[0] # Name of the sample\n",
    "        with czifile.CziFile(file_path) as czi:\n",
    "            data = czi.asarray() # Read confocal image data from .czi file\n",
    "        data_squeezed = np.squeeze(data) # Squeeze data to remove unwanted dimensions/metadata and retrieve image data\n",
    "        image = data_squeezed \n",
    "        mip_image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8) # Normalise image to uint8\n",
    "        mip_image_rgb = cv2.cvtColor(mip_image, cv2.COLOR_GRAY2RGB)\n",
    "        gray_image = cv2.cvtColor(mip_image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        clahe_image = clahe.apply(gray_image) # Apply CLAHE for contrast enhacement\n",
    "        _, otsu_mask = cv2.threshold(clahe_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # Otsu thresholding\n",
    "        output_mip_path = os.path.join(output_path, f\"{sampleID}.tiff\") # Define output MIP path\n",
    "        output_mask_path = os.path.join(output_path, f\"{sampleID}_mask.tiff\") # Define output mask path\n",
    "        return image, mip_image, gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {sampleID}: {e}\") # Print error message if processing fails\n",
    "        return None, None, None, None\n",
    "\n",
    "def load_and_process_czi_double(file_path, file_name, output_path, channel = channel):\n",
    "    \"\"\"\n",
    "    Loads and processes a fluorescent image (.czi file) with two or more channels, \n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Full path to the .czi file.\n",
    "        file_name (str): File name used to derive the sample ID.\n",
    "        output_path (str): Directory where output images will be saved.\n",
    "        channel (int): Channel index. For example mCherry = 0, EGFP = 1, DAPI = 2, etc.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            image (ndarray): Raw image data after squeezing dimensions.\n",
    "            mip_image (ndarray): Normalized maximum-intensity projection (MIP) image in uint8.\n",
    "            gray_image (ndarray): Greyscale MIP image.\n",
    "            clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "            otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "            output_mip_path (str): Path for saving the MIP image.\n",
    "            output_mask_path (str): Path for saving the Otsu mask image.\n",
    "        Returns (None, None, None, None) if processing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sampleID = file_name.split('_MaxInt')[0] # Name of the sample\n",
    "        with czifile.CziFile(file_path) as czi:\n",
    "            data = czi.asarray() # Read confocal image data from .czi file                     \n",
    "        data_squeezed = np.squeeze(data) # Squeeze data to remove unwanted dimensions/metadata\n",
    "        image = data_squeezed[channel] # Retrieve image data from the specified channel\n",
    "        mip_image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8) # Normalise image to uint8\n",
    "        mip_image_rgb = cv2.cvtColor(mip_image, cv2.COLOR_GRAY2RGB)\n",
    "        gray_image = cv2.cvtColor(mip_image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "        clahe_image = clahe.apply(gray_image) # Apply CLAHE for contrast enhacement\n",
    "        _, otsu_mask = cv2.threshold(clahe_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # Otsu thresholding\n",
    "        output_mip_path = os.path.join(output_path, f\"{sampleID}.tiff\") # Define output MIP path\n",
    "        output_mask_path = os.path.join(output_path, f\"{sampleID}_mask.tiff\") # Define output mask path\n",
    "        return image, mip_image, gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {sampleID}: {e}\") # Print error message if processing fails\n",
    "        return None, None, None, None\n",
    "\n",
    "def save_plot_as_pdf(fig, output_path, dpi=pdf_dpi):\n",
    "    \"\"\"\n",
    "    Save a Matplotlib figure to a PDF file.\n",
    "\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): Figure to save.\n",
    "        output_path (str): Output path to save the PDF file.\n",
    "        dpi (int): Resolution to use when saving.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fig.savefig(output_path, format='pdf', dpi=dpi, bbox_inches='tight') # Save figure as PDF\n",
    "        print(f\"Plot saved as PDF: {output_path}\")\n",
    "    except Exception as e: # Print error message if saving fails\n",
    "        print(f\"Error saving plot as PDF: {e}\")\n",
    "\n",
    "def display_and_save_mip_otsu(gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path):\n",
    "    \"\"\"\n",
    "    Display MIP, CLAHE, and Otsu mask panels and save images.\n",
    "    \n",
    "    Args:\n",
    "        gray_image (ndarray): Greyscale MIP image.\n",
    "        clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "        otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "        output_mip_path (str): Path for saving the MIP image.\n",
    "        output_mask_path (str): Path for saving the Otsu mask image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 5)) # Create figure with 3 panels\n",
    "    axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "    axes[0].set_title(\"Maximum Intensity Projection (MIP)\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(clahe_image, cmap=\"gray\") # Display CLAHE processed image\n",
    "    axes[1].set_title(\"Clahe processed image\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[2].imshow(otsu_mask, cmap=\"gray\") # Display Otsu's threshold mask\n",
    "    axes[2].set_title(\"Otsu’s Threshold Mask\")\n",
    "    axes[2].axis(\"off\")\n",
    "    plt.show() # Show the figure\n",
    "    cv2.imwrite(output_mip_path, gray_image) # Save MIP image\n",
    "    cv2.imwrite(output_mask_path, otsu_mask) # Save Otsu mask image\n",
    "    print(f\"Images saved: {output_mip_path} and {output_mask_path}\")\n",
    "\n",
    "def visualize_segmented_regions(gray_image, seg_im, cmap_name='hsv', min_vessel_size = min_vessel_size):\n",
    "    \"\"\"\n",
    "    Visualise labelled vessel segments overlaid on the greyscale image.\n",
    "    \n",
    "    Args:\n",
    "        gray_image (ndarray): Greyscale MIP image for background.\n",
    "        seg_im (ndarray): Binary vessel segmentation mask.\n",
    "        cmap_name (str): Matplotlib colormap name for segment colouring.\n",
    "        min_vessel_size (int): Minimum segment size to keep (pixels).\n",
    "\n",
    "    Returns:\n",
    "        labeled_segments (ndarray): Labelled segmentation image with unique integer labels for each segment.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gray_image_norm = (gray_image - gray_image.min()) / (gray_image.max() - gray_image.min()) # Normalise greyscale image for better visualisation\n",
    "        labeled_segments = label(seg_im) # Label each vessel segment\n",
    "        num_labels = np.max(labeled_segments) # Get number of unique segments\n",
    "        labeled_segments = remove_small_objects(labeled_segments, min_size=min_vessel_size) # Remove small vessel segments based on minimum vessel size\n",
    "        if num_labels == 0: # Check if any segments are detected\n",
    "            print(\"No segments detected.\")\n",
    "            return None\n",
    "        cmap = matplotlib.colormaps.get_cmap(cmap_name) # Generate colours from the chosen colourmap\n",
    "        colors = cmap(np.linspace(0, 1, num_labels))[:, :3] # Get RGB values for each label\n",
    "        overlay = label2rgb(labeled_segments, image=gray_image_norm, bg_label=0, alpha=0.6, colors=colors) # Overlay coloured segments on greyscale image\n",
    "        # Create a figure\n",
    "        fig, ax = plt.subplots(figsize=(8, 6)) # Set figure size\n",
    "        ax.imshow(overlay, cmap='gray') # Display overlay image\n",
    "        ax.set_title(\"Vessel Segmentation Visualization\")\n",
    "        for region in regionprops(labeled_segments): # Loop through each labelled region\n",
    "            centroid = region.centroid # Plot segment labels at centroids\n",
    "            ax.text(centroid[1], centroid[0], str(region.label), color='white', fontsize=8, ha='center', va='center', fontweight='bold')\n",
    "        ax.axis('off') # Remove axes\n",
    "        plt.show() # Show the figure\n",
    "        return labeled_segments  # Return labelled segments for further processing\n",
    "    except Exception as e: \n",
    "        print(f\"Error visualizing segmented regions: {e}\") # Print error message if visualization fails\n",
    "        return None\n",
    "    \n",
    "def remove_selected_segments(labeled_segments, remove_list):\n",
    "    \"\"\"\n",
    "    Manual curation: Remove user-selected labelled segments from a segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        labeled_segments (ndarray): Labelled segmentation image.\n",
    "        remove_list (list[int] or None): Segment labels to remove. Use the segment numbers displayed in the visualisation for reference. If None, no segments will be removed.\n",
    "\n",
    "    Returns:\n",
    "        cleaned_mask (ndarray): Binary mask with curated segments \n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mask = np.isin(labeled_segments, remove_list, invert=True) # Create mask to exclude selected segments\n",
    "        cleaned_mask = labeled_segments * mask # Apply mask to labelled segments\n",
    "        return cleaned_mask > 0 # Return manually curated binary mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing selected segments: {e}\") # Print error message if removal fails\n",
    "        return None\n",
    "\n",
    "def segment_and_analyze_vessels(data_path, file_name, image, gray_image, clahe_image, otsu_mask, output_path,\n",
    "                                im_filter=seg_method, sigma1=sigma1, hole_size=hole_size, \n",
    "                                ditzle_size=ditzle_size, thresh=thresh):\n",
    "    \"\"\"\n",
    "    Vessel segmentation, optional apply of manual curation and results visualisation\n",
    "    \n",
    "    Args:\n",
    "        data_path (str): Directory containing the input image (used for labeling).\n",
    "        file_name (str): File name used to derive the sample ID.\n",
    "        image (ndarray): Raw image data used for segmentation.\n",
    "        gray_image (ndarray): Greyscale MIP image.\n",
    "        clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "        otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "        output_path (str): Directory for saving figures.\n",
    "        im_filter (str): Vessel enhancement filter name (meijering, frangi, sato or jerman).\n",
    "        sigma1 (range): Sigma range for vessel enhancement.\n",
    "        hole_size (int): Max hole size to fill in the mask.\n",
    "        ditzle_size (int): Max size of small objects to remove.\n",
    "        thresh (int): Threshold for binarisation of the enhanced image.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            vessel_seg (ndarray): Final vessel segmentation mask (curated if manual curation is applied).\n",
    "            remove_list (list[int] or None): Labels removed by the user.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Segment vessels using specified filtering method and parameters\n",
    "        vessel_seg = vm.segment_image(image,\n",
    "                                      im_filter=im_filter, # Vessel segmentation method\n",
    "                                      sigma1=sigma1, # Sigma range for vessel enhancement filter\n",
    "                                      hole_size=hole_size, # Hole size to be filled in the vessel mask\n",
    "                                      ditzle_size=ditzle_size, # Size of small objects to be removed from the vessel mask\n",
    "                                      thresh=thresh) # Threshold value to binarise the vessel enhanced image\n",
    "        seg_im = vessel_seg.astype(np.uint8) # Convert binary mask to uint8 format\n",
    "        # Visualise initial segmentation results\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(15, 5)) # Create figure with 4 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(clahe_image, cmap=\"gray\") # Display CLAHE processed image\n",
    "        axes[1].set_title(\"Clahe processed image\")\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(seg_im, cmap=\"gray\") # Display vessel segmentation image\n",
    "        axes[2].set_title(\"Vessel segmentation image\")\n",
    "        axes[2].axis(\"off\")\n",
    "        axes[3].imshow(otsu_mask, cmap=\"gray\") # Display Otsu's threshold mask\n",
    "        axes[3].set_title(\"Otsu’s Threshold Mask\")\n",
    "        axes[3].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('_MaxInt')[0]\n",
    "        fig_title = f\"{sampleID}_segmentation_mask_prefiltering\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        # Visualise segmented regions with labels for manual curation    \n",
    "        labeled_segments = visualize_segmented_regions(gray_image, seg_im, cmap_name='hsv', min_vessel_size = min_vessel_size) # Visualise segmented regions\n",
    "        sampleID = file_name.split('_MaxInt')[0]\n",
    "        fig_title = f\"{sampleID}_segmentation_labelled\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        # Manual curation: Remove unwanted segments based on user input\n",
    "        remove_list = input(\"Enter segment numbers to remove (comma-separated) or press Enter to skip: \").strip() # Get user input for segments to remove\n",
    "        if remove_list:\n",
    "            remove_list = [int(x) for x in remove_list.split(\",\")] # Convert input string to list of integers\n",
    "            cleaned_mask = remove_selected_segments(labeled_segments, remove_list) # Remove selected segments\n",
    "            labeled_segments = label(cleaned_mask) # Relabel the manually curated mask\n",
    "            vessel_seg = labeled_segments # Update vessel segmentation mask\n",
    "        else:\n",
    "            remove_list = None # No segments removed\n",
    "            cleaned_mask = remove_selected_segments(labeled_segments, remove_list) # Keep original mask\n",
    "            labeled_segments = label(cleaned_mask) \n",
    "            vessel_seg = labeled_segments\n",
    "        # Visualise manually curated segmentation results\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(15, 5)) # Create figure with 4 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\")\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\") # Display MIP\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(clahe_image, cmap=\"gray\") # Display CLAHE processed image\n",
    "        axes[1].set_title(\"Clahe processed image\")\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(cleaned_mask, cmap=\"gray\") # Display manually filtered vessel segmentation image\n",
    "        axes[2].set_title(\"Filtered vessel segmentation image\")\n",
    "        axes[2].axis(\"off\")\n",
    "        axes[3].imshow(otsu_mask, cmap=\"gray\") # Display Otsu's threshold mask\n",
    "        axes[3].set_title(\"Otsu’s Threshold Mask\")\n",
    "        axes[3].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('_MaxInt')[0]\n",
    "        fig_title = f\"{sampleID}_segmentation_mask\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF  \n",
    "        return vessel_seg, remove_list\n",
    "    except Exception as e:\n",
    "        print(f\"Error segmenting vessels for {file_name}: {e}\") # Print error message if segmentation fails\n",
    "        return None    \n",
    "    \n",
    "def calculate_and_print_metrics(label_path, vessel_seg):\n",
    "    \"\"\"\n",
    "    Compute vessel metrics and overlap statistics.\n",
    "\n",
    "    Args:\n",
    "        label_path (str): Path to the labelled image.\n",
    "        vessel_seg (ndarray): Vessel segmentation mask.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            length (float): Vessel length metric.\n",
    "            area (float): Vessel area metric.\n",
    "            conn (float): Connectivity metric.\n",
    "            Q (float): Combined metric of Q = connectivity * length * area.\n",
    "            jaccard (float): Jaccard index between label and segmentation.\n",
    "            label (ndarray): Raw labelled image.\n",
    "            label_im (ndarray): Labelled image cast to uint8.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        label = cv2.imread(label_path, 0) # Load label image\n",
    "        label_im = label.astype(np.uint8) # Convert label image to uint8\n",
    "        seg_im = vessel_seg.astype(np.uint8) # Convert segmentation mask to uint8, [i] is the index of each ROI\n",
    "        length, area, conn, Q = vm.cal(label_im, seg_im) # Calculate vessel metrics: length, area, connectivity and Q factor (combined metric of connectivity * length * area)\n",
    "        jaccard = vm.jaccard(label_im, seg_im) # Calculate Jaccard index between label and segmentation mask\n",
    "        return length, area, conn, Q, jaccard, label, label_im # Return vessel metrics and labelled images\n",
    "    except Exception as e:\n",
    "        print(f\"Error calculating metrics: {e}\") # Print error message if vessel metrics calculation fails\n",
    "        return None\n",
    "\n",
    "def find_branchpoints(skel, min_distance=Branch_dist):\n",
    "    \"\"\"\n",
    "    Detect branchpoints from a skeleton image and removes nearby branchpoints based on a minimum distance threshold.\n",
    "\n",
    "    Args:\n",
    "        skel (ndarray): Skeletonised vessel image.\n",
    "        min_distance (int): Minimum distance between branchpoints (pixels). Users are reccommended to set this parameter based median(vessel_length)\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            edges (ndarray): Skeleton edges after removing branchpoints.\n",
    "            branchpoints (ndarray): Binary image of cleaned branchpoints.\n",
    "    \"\"\"\n",
    "    skel_binary = np.zeros_like(skel) # Create binary skeleton image\n",
    "    skel_binary[skel > 0] = 1 # Binarise skeleton image\n",
    "    skel_index = np.argwhere(skel_binary == True) # Get coordinates of skeleton pixels\n",
    "    tile_sum = [] # List to store sum of neighbourhood pixels\n",
    "    neighborhood_image = np.zeros(skel.shape) # Image to store neighbourhood sums\n",
    "    for i, j in skel_index: # Loop through each skeleton pixel\n",
    "        this_tile = skel_binary[i - 1 : i + 2, j - 1 : j + 2] # Extract 3x3 neighbourhood\n",
    "        tile_sum.append(np.sum(this_tile)) # Sum of neighbourhood pixels\n",
    "        neighborhood_image[i, j] = np.sum(this_tile) # Store sum in neighbourhood image    \n",
    "    branch_points = np.zeros_like(neighborhood_image) # Create branchpoint image\n",
    "    branch_points[neighborhood_image > 3] = 1 # Identify branchpoints (neighbourhood sum > 3)\n",
    "    branch_points = branch_points.astype(np.uint8) # Convert branchpoint image to uint8\n",
    "    branch_coords = np.argwhere(branch_points == 1) # Get coordinates of branchpoints\n",
    "    to_keep = np.ones(len(branch_coords), dtype=bool) # Boolean array to track branchpoints to keep\n",
    "    dists = distance.squareform(distance.pdist(branch_coords)) # Calculate pairwise distances between branchpoints\n",
    "    for i in range(len(branch_coords)): # Loop through each branchpoint\n",
    "        if not to_keep[i]: # Skip if already marked for removal\n",
    "            continue\n",
    "        close = np.where((dists[i] < min_distance) & (dists[i] > 0))[0] # Find nearby branchpoints within min_distance\n",
    "        to_keep[close] = False  # Keep only the first point and remove closeby branchpoints\n",
    "    cleaned_branch_points = np.zeros_like(skel, dtype=np.uint8) # Creates empty image to store filtered branchpoints\n",
    "    for idx in np.where(to_keep)[0]: # Loop through the index of kept branchpoints\n",
    "        y, x = branch_coords[idx] # Get coordinates for each branchpoint\n",
    "        cleaned_branch_points[y, x] = 1 # Mark the location of the branchpoint\n",
    "    edges = skel_binary - cleaned_branch_points # Edges are defined as skeleton pixels minus the cleaned branchpoints\n",
    "    edges[edges < 0] = 0 # Ensures no negative values are stored\n",
    "    branchpoints = cleaned_branch_points # Store filtered branchpoints\n",
    "    return edges.astype(np.uint8), branchpoints\n",
    "\n",
    "def analyze_skeleton(vessel_seg, gray_image, file_name):\n",
    "    \"\"\"\n",
    "    Analyse skeleton and vessel diameter. Visualise skeleton and branchpoints and save figures as PDF.\n",
    "    \n",
    "    Args:\n",
    "        vessel_seg (ndarray): Vessel segmentation mask.\n",
    "        gray_image (ndarray): Greyscale MIP image.\n",
    "        file_name (str): File name used to derive the sample ID.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            skel (ndarray): Skeletonised image.\n",
    "            edges (ndarray): Skeleton edges with branchpoints removed.\n",
    "            edge_labels (ndarray): Labelled edges image.\n",
    "            branchpoints (ndarray): Binary branchpoint image.\n",
    "            coords (list): Edge coordinates from endpoint analysis.\n",
    "            endpoints (list): Endpoint coordinates from endpoint analysis.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        skel, edges, _ = vm.skeletonize_vm(vessel_seg, method=skel_method) # Calculate skeleton metrics and edges of each image, [i] is the index of each ROI\n",
    "        _, edge_labels = cv2.connectedComponents(edges) # Label connected edges with a unique identifier\n",
    "        _, branchpoints = find_branchpoints(skel) # Define branhpoints (refined from find_branchpoints)\n",
    "        coords, endpoints = vm.find_endpoints(edges) # Find coordinates of each edge for further analysis and visualisation\n",
    "        # Visualise skeleton plot\n",
    "        cmap1 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(1, 1, 1, 0), (0, 0, 0, 1)]) # Colourmap for skeleton (transparent to black)\n",
    "        cmap2 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(1, 1, 1, 0), (1, 0, 0, 1)]) # Colourmap for overlay (transparent to red)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5)) # Create a figure with 3 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\") \n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(skel, cmap=cmap1) # Display skeleton\n",
    "        axes[1].set_title(\"Skeleton Plot\") \n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(gray_image, cmap=\"gray\") # Display overlay of skeleton over MIP\n",
    "        axes[2].imshow(skel, cmap=cmap2)\n",
    "        axes[2].set_title(\"Overlap\")\n",
    "        axes[2].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('_MaxInt')[0]\n",
    "        fig_title = f\"{sampleID}_skeleton_plot\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        # Visualise skeleton lines    \n",
    "        kernel = np.ones((10, 10), np.uint8)  # Adjust kernel size to make branchpoints bigger \n",
    "        branchpoints_dilated = cv2.dilate(branchpoints.astype(np.uint8), kernel, iterations=1) # Dilate branchpoints to make them more visible on the image (only for visualisation purposes)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5)) # Create a figure with 3 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(branchpoints_dilated, cmap='gray_r') # Display branchpoints\n",
    "        axes[1].set_title(\"Branchpoints\")\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(gray_image, cmap=\"gray\") # Display overlay of branchpoints over MIP\n",
    "        axes[2].imshow(branchpoints_dilated, cmap=cmap2)\n",
    "        axes[2].set_title(\"Overlap\")\n",
    "        axes[2].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('_MaxInt')[0]\n",
    "        fig_title = f\"{sampleID}_branchpoint_plot\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        return skel, edges, edge_labels, branchpoints, coords, endpoints\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing skeleton: {e}\") # Print error message if skeletonisation fails\n",
    "        return None\n",
    "    \n",
    "def is_outlier(series, threshold_low=threshold_low, threshold_high=threshold_high):\n",
    "    \"\"\"\n",
    "    Identify outliers using Median Absolute Deviation (MAD).\n",
    "\n",
    "    Args:\n",
    "        series (pandas.Series): Series of numeric values to calculate central tendency.\n",
    "        threshold_low (float): Lower MAD threshold.\n",
    "        threshold_high (float): Upper MAD threshold.\n",
    "\n",
    "    Returns:\n",
    "        pandas.Series: Boolean mask where True indicates an outlier.\n",
    "    \"\"\"\n",
    "    median = series.median() # Calculates central tendency using median\n",
    "    mad = median_abs_deviation(series) # Calculates non-scaled MAD dispersion\n",
    "    # Compute assymetric bounds using provided thresholds\n",
    "    lower_bound = median - threshold_low * mad # Lower threshold\n",
    "    upper_bound = median + threshold_high * mad # Upper threshold\n",
    "    return (series < lower_bound) | (series > upper_bound) # Return a boolean with outliers\n",
    "\n",
    "def DF_filtering(df):\n",
    "    \"\"\"\n",
    "    Filter outliers from each column of a DataFrame using MAD.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame to filter column-wise based on MAD outlier analysis.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with outliers removed per column.\n",
    "    \"\"\"\n",
    "    filtered_dict = {} # Empty dictionary to store filtered dataframes\n",
    "    for column in df.columns: # Iterate through each column \n",
    "        data = df[column].dropna()  # Removes missing values to avoid propagating NaNs into MAD and comparisons\n",
    "        outliers = is_outlier(data)  # Compute outlier mask for the current column\n",
    "        filtered_data = data[~outliers]  # Keep only non-outlier values\n",
    "        filtered_dict[column] = filtered_data.reset_index(drop=True) # Reset index and store filtered data in the dictionary\n",
    "    filtered_values_df = pd.DataFrame(filtered_dict) # Build new dataframe with filtered results\n",
    "    return filtered_values_df\n",
    "\n",
    "def analyze_vessel_diameters(image, vessel_seg, edge_labels, gray_image, file_name):\n",
    "    \"\"\"\n",
    "    Compute vessel diameters and visualise diameter crosslines.\n",
    "\n",
    "    Args:\n",
    "        image (ndarray): Raw image data used for diameter extraction.\n",
    "        vessel_seg (ndarray): Vessel segmentation mask.\n",
    "        edge_labels (ndarray): Labelled edges image from skeletonisation.\n",
    "        gray_image (ndarray): Greyscale MIP image.\n",
    "        file_name (str): File name used to derive the sample ID.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            diam_values (list[float]): Diameter values in pixels.\n",
    "            viz (ndarray): Visualisation image of diameter crosslines.\n",
    "            filtered_diam_values (pandas.DataFrame): MAD-filtered diameters.\n",
    "        Returns ([], None, None) on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        viz, diameters = vm.whole_anatomy_diameter(image, vessel_seg, edge_labels) # Extract diameter measurements from the entire ROI\n",
    "        cmap2 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(1, 1, 1, 0), (1, 0, 0, 1)]) # Define colourmap for overlay (transparent to red)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5)) # Figure with 3 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(viz, cmap=\"gray_r\") # Display diameter crosslines\n",
    "        axes[1].set_title(\"Diameters\")\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(gray_image, cmap=\"gray\") # Display overlay of diameter crosslines over MIP\n",
    "        axes[2].imshow(viz, cmap=cmap2)\n",
    "        axes[2].set_title(\"Overlap\")\n",
    "        axes[2].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('.tiff')[0]\n",
    "        fig_title = f\"{sampleID}_diameter_plot\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        num_diameters = diameters[-1][0] # Re-index diameters with unique identifiers after previous diameter removal\n",
    "        indexed_diameters = [] # Empty list to store new indexed diameters\n",
    "        for new_index in range(1, num_diameters + 1): # Loop through each diameter identifier\n",
    "            found = next((d for d in diameters if d[0] == new_index), None) # Find unique identifiers\n",
    "            if found:\n",
    "                indexed_diameters.append((new_index, found[1])) # If vessel ID was found, keep identifier\n",
    "        filtered_diameters = [(idx, diam) for idx, diam in indexed_diameters if diam > 0] # Remove crosslines that present diameters with zero values\n",
    "        diam_values = [diam for idx, diam in filtered_diameters] # Extract only positive diameter values        \n",
    "        filtered_diam_values = DF_filtering(pd.DataFrame(diam_values, columns=['Diameter (px)'])) # MAD-based filtering of outliers\n",
    "        return diam_values, viz, filtered_diam_values  # Return the diameter values\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing vessel diameters: {e}\") # Print error message if diameter analysis fails\n",
    "        return [], None, None  # Return an empty list in case of an error\n",
    "\n",
    "def visualize_vessel_metrics(edge_labels, diam_values, scale = scale):\n",
    "    \"\"\"\n",
    "    Calculate vessel length, tortuosity, and diameter metrics and performs MAD filtering.\n",
    "\n",
    "    Args:\n",
    "        edge_labels (ndarray): Labelled edges image from skeletonisation.\n",
    "        diam_values (list[float]): Vessel diameter values in pixels.\n",
    "        scale (float): Pixels per micron for spatial conversion. Users need to set this parameter based on the imaging resolution of their dataset.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            length (ndarray): Segment lengths in pixels.\n",
    "            vessel_len (float): Mean segment length in pixels.\n",
    "            tort (ndarray): Tortuosity values per segment.\n",
    "            vessel_tor (float): Mean tortuosity.\n",
    "            diam_values_um (ndarray): Diameters converted to microns.\n",
    "            length_um (ndarray): Segment lengths converted to microns.\n",
    "            filtered_length_df (pandas.DataFrame): MAD-filtered lengths (pixels).\n",
    "            filtered_length_um_df (pandas.DataFrame): MAD-filtered lengths (microns).\n",
    "            filtered_diam_values_df (pandas.DataFrame): MAD-filtered diameters (pixels).\n",
    "            filtered_diam_values_um_df (pandas.DataFrame): MAD-filtered diameters (microns).\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        _, length = vm.vessel_length(edge_labels) # Calculate the length of each segment (pixels)\n",
    "        vessel_len = np.mean(length) # Compute the mean of segment lengths\n",
    "        tort, _ = vm.tortuosity(edge_labels) # Calculate tortuosity values\n",
    "        vessel_tor = np.mean(tort) # Compute the mean tortuosity\n",
    "        tort = np.array(tort) # Transform values into array\n",
    "        # Spatial unit convertion: pixels to microns\n",
    "        diam_values_um = np.array(diam_values) / scale # Convert diameter values\n",
    "        length_um = length / scale # Convert segment length values\n",
    "        filtered_length_df = DF_filtering(pd.DataFrame(length)) # Filter outliers for segment length in pixels\n",
    "        filtered_length_um_df = DF_filtering(pd.DataFrame(length_um)) # Filter outliers for segment length in microns\n",
    "        filtered_diam_values_df = DF_filtering(pd.DataFrame(diam_values)) # Filter outliers for vessel diameters in pixels\n",
    "        filtered_diam_values_um_df = DF_filtering(pd.DataFrame(diam_values_um)) # Filter outliers for vessel diameters in microns\n",
    "        return length, vessel_len, tort, vessel_tor, diam_values_um, length_um, filtered_length_df, filtered_length_um_df, filtered_diam_values_df, filtered_diam_values_um_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualizing vessel metrics: {e}\") # Print error message if vessel measurement fails\n",
    "        return None\n",
    "\n",
    "def analyze_vessel_network(image, vessel_seg, edges, label, scale = scale, window = window_size):\n",
    "    \"\"\"\n",
    "    Compute network-level metrics such as total length and density.\n",
    "\n",
    "    Args:\n",
    "        image (ndarray): Raw image data.\n",
    "        vessel_seg (ndarray): Vessel segmentation mask.\n",
    "        edges (ndarray): Skeleton edges image.\n",
    "        label (ndarray): Labelled image for branchpoint density.\n",
    "        scale (float): Pixels per micron for spatial conversion.\n",
    "        window (int): Window size (microns) for density binning.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            net_length (float): Total network length in pixels.\n",
    "            net_length_um (float): Total network length in microns.\n",
    "            density (float): Mean vessel density.\n",
    "            density_array (ndarray): Bin density values.\n",
    "            overlay (ndarray): Density overlay image.\n",
    "            vessel_density (float): Fraction of vessel in micron².\n",
    "            bp_density (tuple): Branchpoint density outputs.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    density_scale = np.floor(scale * window).astype(int) # Convert pixel scale to a 10×10 grid corresponding to 100µm² bins\n",
    "    try:\n",
    "        net_length = vm.network_length(edges) # Calculate total network length (sum of vessel segments)\n",
    "        net_length_um = net_length / scale # Convert total network length into microns\n",
    "        density, density_array, overlay = vm.vessel_density(image, vessel_seg, density_scale, density_scale) # Compute vessel density map\n",
    "        vessel_density = sum(density_array) # Number of vessel pixels versus total pixels\n",
    "        bp_density = vm.branchpoint_density(label) # Optional: Calculates branchpoint density\n",
    "        return net_length, net_length_um, density, density_array, overlay, vessel_density, bp_density\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing vessel network: {e}\") # Print error message if network measurements fail\n",
    "        \n",
    "def save_results_to_excel(results, diam_results):\n",
    "    \"\"\"\n",
    "    Save vessel analysis metrics and raw values to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        results (list[list]): Summary metrics per sample.\n",
    "        diam_results (dict): Raw and filtered diameters and length results (pixels and microns).\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Sheet 1: Summary embryo metrics\n",
    "        embryo_metrics = pd.DataFrame(results) # Convert results into a dataframe\n",
    "        # Assign columns names to the summary results sheet\n",
    "        embryo_metrics.columns = [\"File name\", \"Area\", \"Connectivity\", \"Q\", \"Jaccard\",\n",
    "                                  \"Mean raw vessel length (px)\", \"Mean raw vessel Length (um)\",\n",
    "                                  \"Mean vessel length (px)\", \"Mean vessel Length (um)\",\n",
    "                                  \"Mean raw vessel diameter (px)\", \"Mean raw vessel diameter (um)\",\n",
    "                                  \"Mean vessel diameter (px)\", \"Mean vessel diameter (um)\", \n",
    "                                  \"Vessel Tortuosity\", \"Network Length (px)\", \"Network Length (um)\", \n",
    "                                  \"Vessel_density\", \"Branchpoints\"]\n",
    "        # Sheet 2: Raw and filtered diameter values (px)\n",
    "        diam_values_df = pd.DataFrame(diam_results[\"diam_values\"]).transpose() # Convert entries into dataframe and transpose so each row corresponds to an image\n",
    "        diam_values_df.columns = [f\"Diameter {i+1}\" for i in range(diam_values_df.shape[1])] # Rename columns with diameter identifiers for each embryo\n",
    "        # Same for MAD-filtered diameter values\n",
    "        filtered_diam_values_df = pd.DataFrame(diam_results[\"filtered_diam_values\"]).transpose()\n",
    "        filtered_diam_values_df.columns = [f\"Diameter {i+1}\" for i in range(filtered_diam_values_df.shape[1])]\n",
    "        # Sheet 3: Raw and filtered diameter values (µm)\n",
    "        diam_values_um_df = pd.DataFrame(diam_results[\"diam_values_um\"]).transpose()\n",
    "        diam_values_um_df.columns = [f\"Diameter {i+1} (um)\" for i in range(diam_values_um_df.shape[1])]\n",
    "        filtered_diam_values_um_df = pd.DataFrame(diam_results[\"filtered_diam_values_um\"]).transpose()\n",
    "        filtered_diam_values_um_df.columns = [f\"Diameter {i+1}\" for i in range(filtered_diam_values_um_df.shape[1])]\n",
    "        # Sheet 4: Vessel Lengths (px)\n",
    "        vessel_lengths_df = pd.DataFrame(diam_results[\"length\"]).transpose()\n",
    "        vessel_lengths_df.columns = [f\"Length {i+1}\" for i in range(vessel_lengths_df.shape[1])]\n",
    "        filtered_vessel_lengths_df = pd.DataFrame(diam_results[\"filtered_length\"]).transpose()\n",
    "        filtered_vessel_lengths_df.columns = [f\"Length {i+1}\" for i in range(filtered_vessel_lengths_df.shape[1])]\n",
    "        # Sheet 5: Vessel Lengths (µm)\n",
    "        vessel_lengths_um_df = pd.DataFrame(diam_results[\"length_um\"]).transpose()\n",
    "        vessel_lengths_um_df.columns = [f\"Length {i+1}\" for i in range(vessel_lengths_um_df.shape[1])]\n",
    "        filtered_vessel_lengths_um_df = pd.DataFrame(diam_results[\"filtered_length_um\"]).transpose()\n",
    "        filtered_vessel_lengths_um_df.columns = [f\"Length {i+1}\" for i in range(filtered_vessel_lengths_um_df.shape[1])]\n",
    "        # Save results to Excel\n",
    "        output_excel_path = os.path.join(output_path, f\"{output_name}.xlsx\") # Construct the output path under within the working directory\n",
    "        with pd.ExcelWriter(output_excel_path) as writer:\n",
    "            # Write each DataFrame to a separate sheet\n",
    "            embryo_metrics.to_excel(writer, sheet_name=\"Embryo Metrics\", index=False)\n",
    "            diam_values_df.to_excel(writer, sheet_name=\"Diameter Values\", index=False)\n",
    "            filtered_diam_values_df.to_excel(writer, sheet_name=\"MAD filtered diameter Values\", index=False)\n",
    "            diam_values_um_df.to_excel(writer, sheet_name=\"Diameter Values (um)\", index=False)\n",
    "            filtered_diam_values_um_df.to_excel(writer, sheet_name=\"MAD filtered diameter Values (um)\", index=False)\n",
    "            vessel_lengths_df.to_excel(writer, sheet_name=\"Vessel Lengths\", index=False)\n",
    "            filtered_vessel_lengths_df.to_excel(writer, sheet_name=\"MAD filtered vessel lengths\", index=False)\n",
    "            vessel_lengths_um_df.to_excel(writer, sheet_name=\"Vessel Lengths (um)\", index=False)\n",
    "            filtered_vessel_lengths_um_df.to_excel(writer, sheet_name=\"MAD filtered vessel lengths (um)\", index=False)\n",
    "        print(f\"Results saved to {output_excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving results to Excel: {e}\") # Print error message if saving results fail\n",
    "\n",
    "def process_all_files(data_path, output_path):\n",
    "    \"\"\"\n",
    "    Process all single-channel images from the input directory.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Directory containing input images.\n",
    "        output_path (str): Directory for saving outputs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    file_names = [f for f in os.listdir(data_path) if f.startswith(name_start) and f.endswith(\".czi\")] # Find all images matching naming pattern\n",
    "    all_results = [] # Empty list to store final metrics per embryo\n",
    "    # Empty dictionary to store vessel metrics across samples\n",
    "    all_diam_results = {\n",
    "        \"diam_values\": [],\n",
    "        \"filtered_diam_values\": [],\n",
    "        \"diam_values_um\": [],\n",
    "        \"filtered_diam_values_um\": [],\n",
    "        \"length\": [],\n",
    "        \"filtered_length\": [],\n",
    "        \"length_um\": [],\n",
    "        \"filtered_length_um\": [],\n",
    "    }\n",
    "    for file_name in file_names: # Loop through each file found in directory\n",
    "        file_path = os.path.join(data_path, file_name) # Find the full file path for each image\n",
    "        sampleID = file_name.split('_MaxInt')[0] # Retrieve sample identifier\n",
    "        print(f\"\\n--- Processing {sampleID} ---\")\n",
    "        # Load and process the image from the .czi file\n",
    "        image, mip_image, gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path = load_and_process_czi(file_path, file_name, output_path)\n",
    "        if mip_image is None:\n",
    "            continue  # Skip to the next file if loading failed\n",
    "        display_and_save_mip_otsu(gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path)\n",
    "        vessel_seg, _ = segment_and_analyze_vessels(data_path, file_name, image, gray_image, clahe_image, otsu_mask, output_path,\n",
    "                                                                  im_filter=seg_method, sigma1=sigma1, hole_size=hole_size, \n",
    "                                                                  ditzle_size=ditzle_size, thresh=thresh\n",
    "                                                                  ) # Vessel segmentation and topology analysis\n",
    "        if vessel_seg is None: \n",
    "            continue # Skip to the next file if segmentation failed\n",
    "        label_path = output_mask_path # Use mask path for metrics function\n",
    "        length, area, conn, Q, jaccard, label, _ = calculate_and_print_metrics(label_path, vessel_seg) # Calculate vessel metrics\n",
    "        skel, edges, edge_labels, _, _, _ = analyze_skeleton(vessel_seg, gray_image, file_name) # Perform skeletonisation and branchpoint analysis\n",
    "        diam_values, viz, filtered_diam_values = analyze_vessel_diameters(image, vessel_seg, edge_labels, gray_image,file_name) # Measure vessel diameters\n",
    "        # Calculate diameter and vessel length metrics, including spatial conversion\n",
    "        (length, vessel_len, _, vessel_tor, diam_values_um, length_um, filtered_length_df,\n",
    "         filtered_length_um_df, filtered_diam_values_df, filtered_diam_values_um_df) = visualize_vessel_metrics(edge_labels, diam_values, scale = scale)\n",
    "        # Calculate overall network metrics\n",
    "        net_length, net_length_um, _, _, _, vessel_density, bp_density = analyze_vessel_network(image, vessel_seg, edges, label, scale = scale, window = window_size) \n",
    "        # Store metric results in Excel file\n",
    "        all_results.append([sampleID, area, conn, Q, jaccard, vessel_len,\n",
    "                            np.mean(length_um), filtered_length_df.values.mean(), filtered_length_um_df.values.mean(),\n",
    "                            np.mean(diam_values), np.mean(diam_values_um), filtered_diam_values_df.values.mean(), filtered_diam_values_um_df.values.mean(),\n",
    "                            vessel_tor, net_length, net_length_um, vessel_density, len(bp_density[0])])\n",
    "        all_diam_results[\"diam_values\"].append(diam_values)\n",
    "        all_diam_results[\"filtered_diam_values\"].append(filtered_diam_values.values.flatten().tolist())\n",
    "        all_diam_results[\"diam_values_um\"].append(diam_values_um)\n",
    "        all_diam_results[\"filtered_diam_values_um\"].append(filtered_diam_values_um_df.values.flatten().tolist())\n",
    "        all_diam_results[\"length\"].append(length)\n",
    "        all_diam_results[\"filtered_length\"].append(filtered_length_df.values.flatten().tolist())\n",
    "        all_diam_results[\"length_um\"].append(length_um)\n",
    "        all_diam_results[\"filtered_length_um\"].append(filtered_length_um_df.values.flatten().tolist())\n",
    "    \n",
    "    save_results_to_excel(all_results, all_diam_results) # Save summary results to Excel\n",
    "    \n",
    "def process_all_files_double(data_path, output_path):\n",
    "    \"\"\"\n",
    "    Process all multi-channel images from the input directory.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Directory containing input images.\n",
    "        output_path (str): Directory for saving outputs.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    file_names = [f for f in os.listdir(data_path) if f.startswith(name_start) and f.endswith(\"dorsal.czi\")] # Find all images matching naming pattern\n",
    "    all_results = [] # Empty list to store final metrics per embryo\n",
    "    # Empty dictionary to store vessel metrics across samples\n",
    "    all_diam_results = {\n",
    "        \"diam_values\": [],\n",
    "        \"filtered_diam_values\": [],\n",
    "        \"diam_values_um\": [],\n",
    "        \"filtered_diam_values_um\": [],\n",
    "        \"length\": [],\n",
    "        \"filtered_length\": [],\n",
    "        \"length_um\": [],\n",
    "        \"filtered_length_um\": [],\n",
    "    }\n",
    "    for file_name in file_names: # Loop through each file found in directory\n",
    "        file_path = os.path.join(data_path, file_name) # Find the full file path for each image\n",
    "        sampleID = file_name.split('_MaxInt')[0] # Retrieve sample identifier\n",
    "        print(f\"\\n--- Processing {sampleID} ---\")\n",
    "        # Load and process the image from the .czi file\n",
    "        image, mip_image, gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path = load_and_process_czi_double(file_path, file_name, output_path, channel = channel)\n",
    "        if mip_image is None:\n",
    "            continue  # Skip to the next file if loading failed\n",
    "        display_and_save_mip_otsu(gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path)\n",
    "        vessel_seg, _ = segment_and_analyze_vessels(data_path, file_name, image, gray_image, clahe_image, otsu_mask, output_path,\n",
    "                                                                  im_filter=seg_method, sigma1=sigma1, hole_size=hole_size, \n",
    "                                                                  ditzle_size=ditzle_size, thresh=thresh\n",
    "                                                                  ) # Vessel segmentation and topology analysis\n",
    "        if vessel_seg is None: \n",
    "            continue # Skip to the next file if segmentation failed\n",
    "        label_path = output_mask_path # Use mask path for metrics function\n",
    "        length, area, conn, Q, jaccard, label, _ = calculate_and_print_metrics(label_path, vessel_seg) # Calculate vessel metrics\n",
    "        skel, edges, edge_labels, _, _, _ = analyze_skeleton(vessel_seg, gray_image, file_name) # Perform skeletonisation and branchpoint analysis\n",
    "        diam_values, viz, filtered_diam_values = analyze_vessel_diameters(image, vessel_seg, edge_labels, gray_image,file_name) # Measure vessel diameters\n",
    "        # Calculate diameter and vessel length metrics, including spatial conversion\n",
    "        (length, vessel_len, _, vessel_tor, diam_values_um, length_um, filtered_length_df,\n",
    "         filtered_length_um_df, filtered_diam_values_df, filtered_diam_values_um_df) = visualize_vessel_metrics(edge_labels, diam_values, scale = scale)\n",
    "        # Calculate overall network metrics\n",
    "        net_length, net_length_um, _, _, _, vessel_density, bp_density = analyze_vessel_network(image, vessel_seg, edges, label, scale = scale, window = window_size) \n",
    "        # Store metric results in Excel file\n",
    "        all_results.append([sampleID, area, conn, Q, jaccard, vessel_len,\n",
    "                            np.mean(length_um), filtered_length_df.values.mean(), filtered_length_um_df.values.mean(),\n",
    "                            np.mean(diam_values), np.mean(diam_values_um), filtered_diam_values_df.values.mean(), filtered_diam_values_um_df.values.mean(),\n",
    "                            vessel_tor, net_length, net_length_um, vessel_density, len(bp_density[0])])\n",
    "        all_diam_results[\"diam_values\"].append(diam_values)\n",
    "        all_diam_results[\"filtered_diam_values\"].append(filtered_diam_values.values.flatten().tolist())\n",
    "        all_diam_results[\"diam_values_um\"].append(diam_values_um)\n",
    "        all_diam_results[\"filtered_diam_values_um\"].append(filtered_diam_values_um_df.values.flatten().tolist())\n",
    "        all_diam_results[\"length\"].append(length)\n",
    "        all_diam_results[\"filtered_length\"].append(filtered_length_df.values.flatten().tolist())\n",
    "        all_diam_results[\"length_um\"].append(length_um)\n",
    "        all_diam_results[\"filtered_length_um\"].append(filtered_length_um_df.values.flatten().tolist())\n",
    "    \n",
    "    save_results_to_excel(all_results, all_diam_results) # Save summary results to Excel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Run samples - Single channel](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "process_all_files(data_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[Run samples - Two or more channels](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "process_all_files_double(data_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
