{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8eefb66",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Import packages](#toc1_)    \n",
    "- [Set up working directory](#toc2_)    \n",
    "- [ISV loss analysis](#toc3_)    \n",
    "  - [Define parameters](#toc3_1_)    \n",
    "  - [Define functions](#toc3_2_)    \n",
    "  - [Perform ISV loss analysis](#toc3_3_)    \n",
    "    - [Run samples in working directory](#toc3_3_1_)    \n",
    "    - [Generate ISV segmentation masks](#toc3_3_2_)    \n",
    "    - [Calculate probability of ISV loss and save results](#toc3_3_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faecaab2",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Import packages](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4b2613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import vessel_metrics as vm\n",
    "import czifile\n",
    "from aicspylibczi import CziFile\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.colors\n",
    "from matplotlib.pyplot import rc_context\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.stats import median_abs_deviation \n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage import color\n",
    "from skimage.color import label2rgb\n",
    "from matplotlib.cm import get_cmap\n",
    "from skimage.morphology import remove_small_objects\n",
    "from aicsimageio import AICSImage, readers\n",
    "from scipy.spatial import distance\n",
    "from skimage.morphology import skeletonize\n",
    "import traceback\n",
    "import gc\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42422e6",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Set up working directory](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3113116f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the path to the working directory and the output folder where the 3D volumes will be saved.\n",
    "Define the name of the files to be processed.\n",
    "\"\"\"\n",
    "data_path = 'path_to_working_directory'\n",
    "output_path = 'path_to_output_directory'\n",
    "file_name = glob.glob(f'{data_path}*.*', recursive = True) # List of file names to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa41177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ensure the output directory exists and that files are read correctly.\n",
    "\"\"\"\n",
    "total_files = len(file_name)\n",
    "print(f\"Wolking forlder contains {total_files} files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9596825",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[ISV loss analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26deb40",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Define parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46999ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please README before running the following code ##\n",
    "\n",
    "## Parameters that the user should define before running VISTA-Z ROI analysis ##\n",
    "\n",
    "    # clahe = (int, int) # CLAHE parameters (clipLimit, tileGridSize)\n",
    "    # ROI_mode = 'square'  or 'polygon'\n",
    "    # ROI_num = int # Number of ROIs to be analysed per sample\n",
    "    # channel = int [0,1,2] # Channel number to be analysed per sample (only if multi-channel images) [0]: mCherry, [1]: EGFP, [2]: DAPI, etc.\n",
    "    # name_start = str # Starting string of the file names to be processed\n",
    "    # pdf_dpi = int # DPI for saving PDF figures\n",
    "    # min_vessel_size = int # Minimum vessel size (in pixels) to be thresholded for analysis\n",
    "    # Vessel segmentation parameters:\n",
    "        # seg_method = str # Vessel segmentation method: 'meijering', 'frangi', 'sato' or 'jerman'\n",
    "        # sigma1 = range(int, int, int) # Sigma range for vessel enhancement filter\n",
    "        # hole_size = int # Maximum hole size to be filled in the vessel mask\n",
    "        # ditzle_size = int # Maximum size of small objects to be removed from the vessel mask\n",
    "        # thresh = int # Threshold value to binarize the vessel enhanced image\n",
    "        # tolerance = float # Tolerance for skeleton pruning (if using 'lee' method)\n",
    "    # Normalisation of vessel metrics to the ROI area:\n",
    "        # scale = float # Scale factor to normalise vessel metrics (microns per pixel)\n",
    "        # z = int # Z-step size (microns) between slices in the 3D image stack\n",
    "    # output_name = str # Name of the output files to be saved (excel file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image pre-processing and ROI selection parameters\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4, 4))\n",
    "ROI_mode = 'square'\n",
    "ROI_num = 1\n",
    "# channel = 0 # Use for multiple channel images\n",
    "name_start = 'flk1EGFP'\n",
    "pdf_dpi = 300\n",
    "\n",
    "# Vessel segmentation parameters\n",
    "min_vessel_size = 500 # Note: User are reccommended to set this parameter after initial analysis based on median(vessel_length) - std(vessel_length)\n",
    "seg_method = 'meijering'\n",
    "sigma1 = range(3, 8, 1)\n",
    "hole_size = 200\n",
    "ditzle_size = 50\n",
    "thresh = 10\n",
    "tolerance = 0.02\n",
    "\n",
    "# Probability of ISV loss parameters\n",
    "ref_name = 'WTsib'\n",
    "target_name = 'mut'\n",
    "scale = 1.2044\n",
    "z = 5\n",
    "\n",
    "# Output file name\n",
    "output_name = \"ISV_Results\"\n",
    "\n",
    "# Define empty lists to store all ROI data\n",
    "all_mipROIs = []\n",
    "all_grayROIs = []\n",
    "all_claheROIs= []\n",
    "all_otsuROIs = []\n",
    "output_ROI_paths = []\n",
    "output_ROImask_paths = []\n",
    "all_coords = []\n",
    "seg_mask = []\n",
    "ISV_labels = []\n",
    "centroids = []\n",
    "embryo_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e384154",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Define functions](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79dedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_roi(image, mode=ROI_mode):\n",
    "    \"\"\"\n",
    "    Interactively select a region of interest (ROI) from a 2D image.\n",
    "    The ROI can be selected as a rotated rectangle (\"square\") or a polygon.\n",
    "    For square selection, the user can rotate and move the box before confirming the ROI.\n",
    "    \n",
    "    Args:\n",
    "        image (ndarray): 2D image from which to select the ROI.\n",
    "        mode (str): Mode of ROI selection, either 'square' or 'polygon'.\n",
    "    \n",
    "    Returns:\n",
    "        roi_img (ndarray): The selected ROI image.\n",
    "        mask (ndarray): Boolean mask of the ROI.\n",
    "        coords (tuple or None): Coordinates of the ROI vertices for polygon selection.\n",
    "        rect (tuple or None): Coordinates of the ROI (center, size, angle) for rectangle selection.\n",
    "        image (ndarray): The original image for reference if no ROI is selected.\n",
    "\n",
    "    \"\"\"\n",
    "    image_disp = (image / image.max() * 255).astype(np.uint8) # Convert image to uint8 for display\n",
    "    roi_img, mask, coords, rect = None, None, None, None\n",
    "    print(\"Press Enter to confirm, 'r' to rotate clockwise, 'e' to rotate counter-clockwise,\")\n",
    "    print(\"'a', 'd', 'w', 's' to move left, right, up, down respectively, and 'c' to cancel.\") \n",
    "    if mode == 'square': # ROI selection as square\n",
    "        from_center = False # Set to True to draw from center\n",
    "        show_crosshair = True # Set to False to hide crosshair\n",
    "        x, y, w, h = cv2.selectROI(\"Select ROI\", image_disp, showCrosshair=show_crosshair, fromCenter=from_center) # Create ROI\n",
    "        if w == 0 or h == 0: # Return full image if no ROI selected\n",
    "            print(\"No ROI selected, returning full image\")\n",
    "            roi_img = image # Full image as ROI\n",
    "            mask = np.ones_like(image, dtype=bool)\n",
    "            coords = None\n",
    "            rect = None\n",
    "            cv2.destroyAllWindows() # Close ROI window\n",
    "            return roi_img, mask, coords, rect\n",
    "        angle = 0 # Defines initial angle\n",
    "        rect = ((x + w / 2, y + h / 2), (w, h), angle) # Define rectangle coordinates\n",
    "        while True: # Rotate and adjust rectangle\n",
    "            display_img = cv2.cvtColor(image_disp, cv2.COLOR_GRAY2BGR)\n",
    "            box = cv2.boxPoints(rect).astype(int) # Get rectangle box points\n",
    "            cv2.drawContours(display_img, [box], 0, (0, 255, 0), 2) # Draw rectangle contour\n",
    "            cv2.imshow(\"Select ROI\", display_img) # Display the image with the rectangle\n",
    "            key = cv2.waitKey(0) & 0xFF # Wait for key press\n",
    "            if key == 13:  # Enter\n",
    "                break \n",
    "            elif key == ord('r'): # Rotate clockwise\n",
    "                rect = (rect[0], rect[1], (rect[2] + 1) % 360)\n",
    "            elif key == ord('e'): # Rotate counter-clockwise\n",
    "                rect = (rect[0], rect[1], (rect[2] - 1) % 360)\n",
    "            elif key == ord('a'): # Move left\n",
    "                cx, cy = rect[0]\n",
    "                rect = ((cx - 10, cy), rect[1], rect[2])\n",
    "            elif key == ord('d'): # Move right\n",
    "                cx, cy = rect[0]\n",
    "                rect = ((cx + 10, cy), rect[1], rect[2])\n",
    "            elif key == ord('w'): # Move up\n",
    "                cx, cy = rect[0]\n",
    "                rect = ((cx, cy - 10), rect[1], rect[2])\n",
    "            elif key == ord('s'): # Move down\n",
    "                cx, cy = rect[0]\n",
    "                rect = ((cx, cy + 10), rect[1], rect[2])\n",
    "            elif key == ord('c'): # Cancel selection\n",
    "                cv2.destroyAllWindows() # Close ROI window\n",
    "                print(\"Cancelled ROI selection.\")\n",
    "                return image, np.ones_like(image, dtype=bool), None, None # Return full image if cancelled\n",
    "        cv2.destroyAllWindows() # Close ROI window\n",
    "        mask_uint8 = np.zeros_like(image, dtype=np.uint8) # Create mask for rotated ROI with zeros\n",
    "        box = cv2.boxPoints(rect).astype(int) # Get rectangle box points\n",
    "        cv2.fillPoly(mask_uint8, [box], 1) # Fill the rectangle area in the mask\n",
    "        mask = mask_uint8.astype(bool) # Convert mask to boolean\n",
    "        ys, xs = np.where(mask) # Get coordinates of the mask\n",
    "        ymin, ymax = ys.min(), ys.max() # Get bounding box of the mask\n",
    "        xmin, xmax = xs.min(), xs.max() \n",
    "        roi_img = image[ymin:ymax, xmin:xmax] # Crop ROI from image\n",
    "        mask = mask[ymin:ymax, xmin:xmax] # Crop mask to ROI\n",
    "        coords = (xmin, ymin, xmax, ymax) # Define ROI coordinates\n",
    "    elif mode == 'polygon': # ROI selection as polygon\n",
    "        points = [] # List to store polygon points\n",
    "        def click_event(event, x, y, flags, param): # Mouse click to record points\n",
    "            if event == cv2.EVENT_LBUTTONDOWN: # Left mouse button click\n",
    "                points.append((x, y)) # Add point to list\n",
    "                cv2.circle(display_img, (x, y), 3, (255, 0, 0), -1) # Draw point on image\n",
    "                cv2.imshow(\"Select ROI\", display_img) # Update display with new point\n",
    "        display_img = cv2.cvtColor(image_disp, cv2.COLOR_GRAY2BGR) \n",
    "        cv2.namedWindow(\"Select ROI\", cv2.WINDOW_NORMAL | cv2.WINDOW_GUI_EXPANDED)\n",
    "        cv2.setWindowProperty(\"Select ROI\", cv2.WND_PROP_TOPMOST, 1)\n",
    "        cv2.imshow(\"Select ROI\", display_img)\n",
    "        cv2.setMouseCallback(\"Select ROI\", click_event)\n",
    "        print(\"Click points to define polygon. Press 'Enter' when done.\") \n",
    "        while True: # Wait for user to finish polygon selection\n",
    "            key = cv2.waitKey(1) & 0xFF # Wait for key press\n",
    "            if key == 13:  # Enter\n",
    "                break\n",
    "            elif key == 27:  # ESC to cancel\n",
    "                points = []\n",
    "                break\n",
    "        cv2.destroyAllWindows() # Close ROI window\n",
    "        if len(points) < 3: # Return full image if no polygon selected\n",
    "            print(\"Polygon not selected, returning full image\")\n",
    "            roi_img = image # Full image as ROI\n",
    "            mask = np.ones_like(image, dtype=bool)\n",
    "            coords = None\n",
    "        else:\n",
    "            mask_uint8 = np.zeros_like(image, dtype=np.uint8) # Create mask for polygon ROI with zeros\n",
    "            cv2.fillPoly(mask_uint8, [np.array(points, dtype=np.int32)], 1) # Fill polygon area in the mask\n",
    "            mask = mask_uint8.astype(bool) # Convert mask to boolean\n",
    "            ys, xs = np.where(mask) # Get coordinates of the mask\n",
    "            ymin, ymax = ys.min(), ys.max() # Get bounding box of the mask\n",
    "            xmin, xmax = xs.min(), xs.max()\n",
    "            roi_img = image[ymin:ymax, xmin:xmax] # Crop ROI from image\n",
    "            coords = (xmin, ymin, xmax, ymax) # Get ROI coordinates\n",
    "    else:\n",
    "        raise ValueError(\"mode must be 'square' or 'polygon'\") # Raise error for invalid mode\n",
    "    return roi_img, mask, coords # Return ROI image, mask, and coordinates\n",
    "\n",
    "def load_and_process_czi_singleROI(file_path, name, output_path, roi = ROI_num):\n",
    "    \"\"\"\n",
    "    Loads and processes a fluorescent image (.czi file) with a single channel, \n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Full path to the .czi file.\n",
    "        name (str): File name used to derive the sample ID.\n",
    "        output_path (str): Directory where output images will be saved.\n",
    "        roi (int): Number of ROIs to be selected and processed per sample.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            image (ndarray): Raw image data after squeezing dimensions.\n",
    "            roi_masks (list[ndarray]): List of binary masks for each selected ROI.\n",
    "            roi_coords (list[tuple]): List of coordinates for each selected ROI.\n",
    "            mip_image (ndarray): Normalized maximum-intensity projection (MIP) image in uint8.\n",
    "            gray_image (ndarray): Greyscale MIP image.\n",
    "            clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "            otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "            output_mip_path (str): Path for saving the MIP image.\n",
    "            output_mask_path (str): Path for saving the Otsu mask image.\n",
    "            mip_imageROI (list[ndarray]): List of MIP images cropped to each selected ROI.\n",
    "            roi_grayROI (list[ndarray]): List of greyscale MIP images cropped to each selected ROI.\n",
    "            roi_claheROI (list[ndarray]): List of CLAHE-enhanced images cropped to each selected ROI.\n",
    "            roi_otsuROI (list[ndarray]): List of Otsu masks cropped to each selected ROI.\n",
    "            output_mipROI_paths (list[str]): List of paths for saving each ROI MIP image.\n",
    "            output_maskROI_paths (list[str]): List of paths for saving each ROI Otsu mask image.\n",
    "        Returns (None, None, None, None) if processing fails.\n",
    "    \"\"\"\n",
    "    # Defining lists to store ROI data\n",
    "    roi_masks = []\n",
    "    roi_coords = []\n",
    "    mip_imageROI = []\n",
    "    roi_grayROI = []\n",
    "    roi_claheROI = []\n",
    "    roi_otsuROI = []\n",
    "    output_mipROI_paths = []\n",
    "    output_maskROI_paths = []\n",
    "    try:\n",
    "        sampleID = name # Name of the sample\n",
    "        with czifile.CziFile(file_path) as czi: \n",
    "            data = czi.asarray() # Read confocal image data from .czi file                        \n",
    "        data_squeezed = np.squeeze(data) # Squeeze data to remove unwanted dimensions/metadata\n",
    "        image = data_squeezed \n",
    "        mip_image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8) # Normalise image to uint8\n",
    "        mip_image_rgb = cv2.cvtColor(mip_image, cv2.COLOR_GRAY2RGB) # Convert grayscale MIP to RGB\n",
    "        gray_image = cv2.cvtColor(mip_image_rgb, cv2.COLOR_RGB2GRAY) # Convert RGB MIP to grayscale\n",
    "        clahe_image = clahe.apply(gray_image) # Apply CLAHE for contrast enhacement\n",
    "        _, otsu_mask = cv2.threshold(clahe_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) # Otsu's thresholding\n",
    "        output_mip_path = os.path.join(output_path, f\"{sampleID}.tiff\") # Define output MIP path\n",
    "        output_mask_path = os.path.join(output_path, f\"{sampleID}_mask.tiff\") # Define output mask path\n",
    "        for i in range(roi): # Loop to selected number of ROIs\n",
    "            _, mask, coords = select_roi(image, mode=ROI_mode) # Select ROIs\n",
    "            roi_masks.append(mask) # Store ROI masks\n",
    "            roi_coords.append(coords) # Store ROI coordinates\n",
    "        for i, (mask, coords) in enumerate(zip(roi_masks, roi_coords)): # Process each ROI\n",
    "            if coords is None: # If coordinates are empty\n",
    "                print(f\"No coordinates selected\") # No ROI selected, entire image used\n",
    "                continue\n",
    "            x1, y1, x2, y2 = coords # Get ROI coordinates\n",
    "            roi_mip = mip_image[y1:y2, x1:x2] # Crop MIP to ROI\n",
    "            roi_gray = gray_image[y1:y2, x1:x2] # Crop grayscale MIP to ROI\n",
    "            roi_clahe = clahe_image[y1:y2, x1:x2] # Crop CLAHE image to ROI\n",
    "            roi_otsu = otsu_mask[y1:y2, x1:x2] # Crop Otsu mask to ROI\n",
    "            mip_imageROI.append(roi_mip) # Store ROI MIP\n",
    "            roi_grayROI.append(roi_gray) # Store ROI grayscale MIP\n",
    "            roi_claheROI.append(roi_clahe) # Store ROI CLAHE image\n",
    "            roi_otsuROI.append(roi_otsu) # Store ROI Otsu mask\n",
    "            output_mipROI_path = os.path.join(output_path, f\"{sampleID}_ROI{i}.tiff\") # Define output ROI MIP path\n",
    "            output_maskROI_path = os.path.join(output_path, f\"{sampleID}_ROI{i}_mask.tiff\") # Define output ROI mask path\n",
    "            output_mipROI_paths.append(output_mipROI_path) # Store output ROI MIP path\n",
    "            output_maskROI_paths.append(output_maskROI_path) # Store output ROI mask path\n",
    "            display_and_save_mip_otsu(roi_gray, roi_clahe, roi_otsu, output_mipROI_path, output_maskROI_path) # Display and save ROI images\n",
    "        return image, roi_masks, roi_coords, mip_image, gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path, mip_imageROI, roi_grayROI, roi_claheROI, roi_otsuROI, output_mipROI_paths, output_maskROI_paths\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {sampleID}: {e}\") # Print error message if processing fails\n",
    "        return None, None, None, None\n",
    "    \n",
    "def save_plot_as_pdf(fig, output_path, dpi=pdf_dpi):\n",
    "    \"\"\"\n",
    "    Save a Matplotlib figure to a PDF file.\n",
    "\n",
    "    Args:\n",
    "        fig (matplotlib.figure.Figure): Figure to save.\n",
    "        output_path (str): Output path to save the PDF file.\n",
    "        dpi (int): Resolution to use when saving.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fig.savefig(output_path, format='pdf', dpi=dpi, bbox_inches='tight') # Save figure as PDF\n",
    "        print(f\"Plot saved as PDF: {output_path}\")\n",
    "    except Exception as e: # Print error message if saving fails\n",
    "        print(f\"Error saving plot as PDF: {e}\")\n",
    "        \n",
    "def display_and_save_mip_otsu(gray_image, clahe_image, otsu_mask, output_mip_path, output_mask_path):\n",
    "    \"\"\"\n",
    "    Display MIP, CLAHE, and Otsu mask panels and save images.\n",
    "    \n",
    "    Args:\n",
    "        gray_image (ndarray): Greyscale MIP image.\n",
    "        clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "        otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "        output_mip_path (str): Path for saving the MIP image.\n",
    "        output_mask_path (str): Path for saving the Otsu mask image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(8, 5)) # Create figure with 3 panels\n",
    "    axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "    axes[0].set_title(\"Maximum Intensity Projection (MIP)\")\n",
    "    axes[0].axis(\"off\")\n",
    "    axes[1].imshow(clahe_image, cmap=\"gray\") # Display CLAHE processed image\n",
    "    axes[1].set_title(\"Clahe processed image\")\n",
    "    axes[1].axis(\"off\")\n",
    "    axes[2].imshow(otsu_mask, cmap=\"gray\") # Display Otsu's threshold mask\n",
    "    axes[2].set_title(\"Otsu’s Threshold Mask\")\n",
    "    axes[2].axis(\"off\")\n",
    "    plt.show() # Show the figure\n",
    "    cv2.imwrite(output_mip_path, gray_image) # Save MIP image\n",
    "    cv2.imwrite(output_mask_path, otsu_mask) # Save Otsu mask image\n",
    "    print(f\"Images saved: {output_mip_path} and {output_mask_path}\")\n",
    "\n",
    "def visualize_segmented_regions(gray_image, seg_im, cmap_name='hsv', min_vessel_size = min_vessel_size):\n",
    "    \"\"\"\n",
    "    Visualise labelled vessel segments overlaid on the greyscale image.\n",
    "    \n",
    "    Args:\n",
    "        gray_image (ndarray): Greyscale MIP image for background.\n",
    "        seg_im (ndarray): Binary vessel segmentation mask.\n",
    "        cmap_name (str): Matplotlib colormap name for segment colouring.\n",
    "        min_vessel_size (int): Minimum segment size to keep (pixels).\n",
    "\n",
    "    Returns:\n",
    "        labeled_segments (ndarray): Labelled segmentation image with unique integer labels for each segment.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        gray_image_norm = (gray_image - gray_image.min()) / (gray_image.max() - gray_image.min()) # Normalise grayscale image for better visualisation\n",
    "        labeled_segments = label(seg_im) # Label each vessel segment\n",
    "        num_labels = np.max(labeled_segments) # Get number of unique segments\n",
    "        labeled_segments = remove_small_objects(labeled_segments, min_size=min_vessel_size) # Remove small vessel segments based on minimum vessel size\n",
    "        if num_labels == 0: # Check if any segments are detected\n",
    "            print(\"No segments detected.\")\n",
    "            return None\n",
    "        cmap = matplotlib.colormaps.get_cmap(cmap_name) # Generate colours from the chosen colourmap\n",
    "        colors = cmap(np.linspace(0, 1, num_labels))[:, :3] # Get RGB values for each label\n",
    "        overlay = label2rgb(labeled_segments, image=gray_image_norm, bg_label=0, alpha=0.6, colors=colors) # Overlay coloured segments on grayscale image\n",
    "        # Create a figure\n",
    "        fig, ax = plt.subplots(figsize=(8, 6)) # Set figure size\n",
    "        ax.imshow(overlay, cmap='gray') # Display overlay image\n",
    "        ax.set_title(\"Vessel Segmentation Visualization\")\n",
    "        for region in regionprops(labeled_segments): # Loop through each labeled region\n",
    "            centroid = region.centroid # Plot segment labels at centroids\n",
    "            ax.text(centroid[1], centroid[0], str(region.label), color='white', fontsize=8, ha='center', va='center', fontweight='bold')\n",
    "        ax.axis('off') # Remove axes\n",
    "        plt.show() # Show the figure\n",
    "        return labeled_segments  # Return labeled segments for further processing\n",
    "    except Exception as e: \n",
    "        print(f\"Error visualizing segmented regions: {e}\") # Print error message if visualization fails\n",
    "        return None\n",
    "    \n",
    "def remove_selected_segments(labeled_segments, remove_list):\n",
    "    \"\"\"\n",
    "    Manual curation: Remove user-selected labelled segments from a segmentation mask.\n",
    "\n",
    "    Args:\n",
    "        labeled_segments (ndarray): Labelled segmentation image.\n",
    "        remove_list (list[int] or None): Segment labels to remove. Use the segment numbers displayed in the visualisation for reference. If None, no segments will be removed.\n",
    "\n",
    "    Returns:\n",
    "        cleaned_mask (ndarray): Binary mask with curated segments \n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mask = np.isin(labeled_segments, remove_list, invert=True) # Create mask to exclude selected segments\n",
    "        cleaned_mask = labeled_segments * mask # Apply mask to labeled segments\n",
    "        return cleaned_mask > 0 # Return manually curated binary mask\n",
    "    except Exception as e:\n",
    "        print(f\"Error removing selected segments: {e}\") # Print error message if removal fails\n",
    "        return None\n",
    "\n",
    "def segment_and_analyze_vessels(file_name, image, gray_image, clahe_image, otsu_mask, output_path, \n",
    "                                im_filter=seg_method, sigma1=sigma1, hole_size=hole_size, \n",
    "                                ditzle_size=ditzle_size, thresh=thresh):\n",
    "    \"\"\"\n",
    "    Vessel segmentation, optional apply of manual curation and results visualisation\n",
    "    \n",
    "    Args:\n",
    "        file_name (str): File name used to derive the sample ID.\n",
    "        image (ndarray): Raw image data used for segmentation.\n",
    "        gray_image (ndarray): Greyscale MIP image.\n",
    "        clahe_image (ndarray): CLAHE-enhanced greyscale image.\n",
    "        otsu_mask (ndarray): Binary mask from Otsu thresholding.\n",
    "        output_path (str): Directory for saving figures.\n",
    "        im_filter (str): Vessel enhancement filter name (meijering, frangi, sato or jerman).\n",
    "        sigma1 (range): Sigma range for vessel enhancement.\n",
    "        hole_size (int): Max hole size to fill in the mask.\n",
    "        ditzle_size (int): Max size of small objects to remove.\n",
    "        thresh (int): Threshold for binarisation of the enhanced image.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            vessel_seg (ndarray): Final vessel segmentation mask (curated if manual curation is applied).\n",
    "            remove_list (list[int] or None): Labels removed by the user.\n",
    "            num_labels (int): Number of labelled segments in the final segmentation mask.\n",
    "        Returns None on failure.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Segment vessels using specified filtering method and parameters\n",
    "        vessel_seg = vm.segment_image(image,\n",
    "                                      im_filter=im_filter, # Vessel segmentation method\n",
    "                                      sigma1=sigma1, # Sigma range for vessel enhancement filter\n",
    "                                      hole_size=hole_size, # Hole size to be filled in the vessel mask\n",
    "                                      ditzle_size=ditzle_size, # Size of small objects to be removed from the vessel mask\n",
    "                                      thresh=thresh) # Threshold value to binarise the vessel enhanced image\n",
    "        seg_im = vessel_seg.astype(np.uint8) # Convert binary mask to uint8 format\n",
    "        # Visualise initial segmentation results\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(15, 5)) # Create figure with 4 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\") # Display MIP\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\")\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(clahe_image, cmap=\"gray\") # Display CLAHE processed image\n",
    "        axes[1].set_title(\"Clahe processed image\")\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(seg_im, cmap=\"gray\") # Display vessel segmentation image\n",
    "        axes[2].set_title(\"Vessel segmentation image\")\n",
    "        axes[2].axis(\"off\")\n",
    "        axes[3].imshow(otsu_mask, cmap=\"gray\") # Display Otsu's threshold mask\n",
    "        axes[3].set_title(\"Otsu’s Threshold Mask\")\n",
    "        axes[3].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('.tiff')[0] \n",
    "        fig_title = f\"{sampleID}_segmentation_mask_prefiltering\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        # Visualise segmented regions with labels for manual curation    \n",
    "        labeled_segments = visualize_segmented_regions(gray_image, seg_im, cmap_name='hsv', min_vessel_size = min_vessel_size) # Visualise segmented regions\n",
    "        sampleID = file_name.split('.tiff')[0]\n",
    "        fig_title = f\"{sampleID}_segmentation_labelled\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF\n",
    "        # Manual curation: Remove unwanted segments based on user input\n",
    "        remove_list = input(\"Enter segment numbers to remove (comma-separated) or press Enter to skip: \").strip() # Get user input for segments to remove\n",
    "        if remove_list:\n",
    "            remove_list = [int(x) for x in remove_list.split(\",\")] # Convert input string to list of integers\n",
    "            cleaned_mask = remove_selected_segments(labeled_segments, remove_list) # Remove selected segments\n",
    "            labeled_segments = label(cleaned_mask) # Relabel the manually curated mask\n",
    "            num_labels = np.max(labeled_segments) # Calculate the maximum number of labelled ISVs\n",
    "            vessel_seg = labeled_segments # Update vessel segmentation mask\n",
    "        else:\n",
    "            remove_list = None # No segments removed\n",
    "            cleaned_mask = remove_selected_segments(labeled_segments, remove_list) # Keep original mask\n",
    "            labeled_segments = label(cleaned_mask) # Relabel the manually curated mask\n",
    "            num_labels = np.max(labeled_segments) # Calculate the maximum number of labelled ISVs\n",
    "            vessel_seg = labeled_segments # Update vessel segmentation mask\n",
    "        # Visualise manually curated segmentation results    \n",
    "        print(f\"Visualising filtered segmentation image\")\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(15, 5)) # Create figure with 4 panels\n",
    "        axes[0].imshow(gray_image, cmap=\"gray\")\n",
    "        axes[0].set_title(\"Maximum Intensity Projection (MIP)\") # Display MIP\n",
    "        axes[0].axis(\"off\")\n",
    "        axes[1].imshow(clahe_image, cmap=\"gray\") # Display CLAHE processed image\n",
    "        axes[1].set_title(\"Clahe processed image\")\n",
    "        axes[1].axis(\"off\")\n",
    "        axes[2].imshow(cleaned_mask, cmap=\"gray\") # Display manually filtered vessel segmentation image\n",
    "        axes[2].set_title(\"Filtered vessel segmentation image\")\n",
    "        axes[2].axis(\"off\")\n",
    "        axes[3].imshow(otsu_mask, cmap=\"gray\") # Display Otsu's threshold mask\n",
    "        axes[3].set_title(\"Otsu’s Threshold Mask\")\n",
    "        axes[3].axis(\"off\")\n",
    "        plt.show() # Show the figure\n",
    "        sampleID = file_name.split('.tiff')[0]\n",
    "        fig_title = f\"{sampleID}_segmentation_mask\" # Title for the figure\n",
    "        output_pdf_path = os.path.join(output_path, f\"{fig_title}.pdf\") # Define output PDF path\n",
    "        save_plot_as_pdf(fig, output_pdf_path) # Save figure as PDF  \n",
    "        return vessel_seg, remove_list, num_labels\n",
    "    except Exception as e:\n",
    "        print(f\"Error segmenting vessels for {file_name}: {e}\") # Print error message if segmentation fails\n",
    "        return None\n",
    "\n",
    "def extract_isv_centroids(vessel_seg):\n",
    "    \"\"\"\n",
    "    Extract centroids of labelled intersegmental vessel (ISV) segments and sort them left-to-right.\n",
    "    \n",
    "    Args:\n",
    "        vessel_seg (ndarray): Labelled vessel segmentation mask with unique integer labels for each segment.\n",
    "        \n",
    "    Returns:\n",
    "        centroids (ndarray): Array of centroids (y, x) for each ISV segment, sorted by increasing x-coordinate (left to right).\n",
    "    \"\"\"\n",
    "    regions = regionprops(vessel_seg) # Extract connected vessel components (each ISV is a unique segment)\n",
    "    centroids = np.array([r.centroid for r in regions])  # Extract centroid (y, x) of each region and convert list into array\n",
    "    order = np.argsort(centroids[:, 1]) # Order ISV from left to right (by increasing x-coordinates)\n",
    "    centroids = centroids[order] # Sort ISV position\n",
    "    return centroids\n",
    "\n",
    "def normalize_x_positions(centroids):\n",
    "    \"\"\"\n",
    "    Normalise x-coordinates of centroids to the range [0, 1].\n",
    "    This allows for comparison of ISV positions across samples with different sizes and scales.\n",
    "    \n",
    "    Args:\n",
    "        centroids (ndarray): Array of centroids (y, x) for each ISV segment.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalised x-coordinates of the centroids, scaled to the range [0, 1].\n",
    "    \"\"\"\n",
    "    x = centroids[:, 1] # Extract only x-coordinates\n",
    "    return (x - x.min()) / (x.max() - x.min()) # Returns normalised x-centroids\n",
    "\n",
    "def detect_lost_isvs(ref_centroids, target_centroids, tol = tolerance):\n",
    "    \"\"\"\n",
    "    Identify ISVs that are missing in a target sample relative to a reference.\n",
    "    \n",
    "    Args:\n",
    "        ref_centroids (ndarray): Array of centroids (y, x) for ISVs in the reference sample (e.g. wild type).\n",
    "        target_centroids (ndarray): Array of centroids (y, x) for ISVs in the target sample (e.g. mutant).\n",
    "        tol (float): Maximum normalised x-distance allowed for an ISV to count as \"matched\" between the reference and target samples. ISVs with no match within this tolerance are considered \"lost\".\n",
    "\n",
    "    Returns:\n",
    "        lost (ndarray): Boolean array indicating which ISVs in the reference sample are \"lost\" in the target sample (True for lost, False for matched).\n",
    "        min_dist (ndarray): Array of minimum normalised x-distances from each reference ISV to the nearest target ISV\n",
    "    \"\"\"\n",
    "    ref_x = normalize_x_positions(ref_centroids)       # Normalise ISV x positions to [0, 1] in the reference sample dataset (e.g. wild type)\n",
    "    target_x = normalize_x_positions(target_centroids) # Normalise ISV x positions to [0, 1] in the target dataset (e.g. mutant)\n",
    "    dist = cdist(ref_x[:, None], target_x[:, None])    # Compute pairwise Euclidean distances between the reference and target samples\n",
    "    min_dist = dist.min(axis=1)  # For each reference ISV, find the nearest target ISV\n",
    "    # tol: Maximum normalised x-distance allowed for an ISV to count as \"matched\"\n",
    "    lost = min_dist > tol  # An ISV is \"lost\" if no ISV is within tolerance\n",
    "    return lost, min_dist # returns ISV possitions and reference to compute probability of ISV loss\n",
    "\n",
    "def plot_loss_probabilities(prob_summary):\n",
    "    \"\"\"\n",
    "    Plot grouped bar chart of ISV loss probabilities for each group.\n",
    "    \n",
    "    Args:\n",
    "        prob_summary (DataFrame): DataFrame containing ISV labels and loss probabilities for each group.\n",
    "    \n",
    "    Returns None\n",
    "    \"\"\"\n",
    "    isvs = prob_summary[\"ISV\"] # Extract ISV labels from the dataframe\n",
    "    groups = [c for c in prob_summary.columns if c != \"ISV\"] # Extract group names (e.g. reference versus target samples)\n",
    "    bar_width = 0.35 # Width of each bar in the grouped barplot\n",
    "    x = np.arange(len(isvs)) # Create x-coordinate positions for each ISV\n",
    "    plt.figure(figsize=(8, 6))\n",
    "     # Colours assigned to each group for plotting\n",
    "    colors = {\n",
    "        ref_name: \"steelblue\",\n",
    "        target_name: \"firebrick\"\n",
    "    }\n",
    "    # Loop through each group and plot its bar series\n",
    "    for i, group in enumerate(groups):\n",
    "        plt.bar(\n",
    "            x + i * bar_width,                  # Shift each bar horizontally\n",
    "            prob_summary[group],                # Height of the bar is defined by the probability of ISV loss\n",
    "            width=bar_width,                    # Bar width\n",
    "            label=group,                        # Labels for legend\n",
    "            color=colors.get(group, \"gray\"),    # Create a predefined grey canvas to colour-coded on top based by group\n",
    "            alpha=0.8                           # Reduce the opacity of the colours\n",
    "        )\n",
    "    plt.xticks(x + bar_width / 2, isvs, rotation=90)        # Set x-axis tick centered between grouped bars\n",
    "    plt.ylabel(\"Probability of ISV loss by position (%)\")   # Title for y-axis\n",
    "    # plt.xlabel(\"ISV index (left → right)\")                # Title for x-axis\n",
    "    # plt.title(\"ISV Loss Probability per Group\")           # Figure title\n",
    "    plt.legend()                                            # Display figure legend within the plot\n",
    "    # Remove top and right spines for visualisation purposes\n",
    "    ax = plt.gca()\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    plt.tight_layout() # Adjust layout to avoid label cutoff\n",
    "    title_fig = 'ISV_loss_probabilities.pdf'\n",
    "    plt.savefig(title_fig, format=\"pdf\")\n",
    "    plt.show()         # Display figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bfcc55",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Perform ISV loss analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338cfb36",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_1_'></a>[Run samples in working directory](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file name and extension. Collect all files in the directory that match the name prefix\n",
    "file_names = [f for f in os.listdir(data_path) if f.startswith(name_start) and f.endswith(\".czi\")]\n",
    "\n",
    "for file_name in file_names: # Loop through each file in the working directory\n",
    "    file_path = os.path.join(data_path, file_name) # Build full path to the file\n",
    "    sampleID = file_name.split('_MaxInt')[0] # Extract sample identifier \n",
    "    print(f\"\\n--- Processing {sampleID} ---\")\n",
    "    (image,                 # Original mage\n",
    "     roi_masks,             # ROI mask\n",
    "     roi_coords,            # ROI coordinates\n",
    "     mip_image,             # Maximum intensity projection (MIP)\n",
    "     gray_image,            # Greyscale MIP\n",
    "     clahe_image,           # CLAHE-enhanced MIP\n",
    "     otsu_mask,             # OTSU threshold mask\n",
    "     output_mip_path,       # Output path for MIP\n",
    "     output_mask_path,      # Output path for mask\n",
    "     mip_imageROI,          # List of ROI MIP images\n",
    "     roi_grayROI,           # List of ROI grayscale images\n",
    "     roi_claheROI,          # List of ROI CLAHE images\n",
    "     roi_otsuROI,           # List of ROI OTSU masks\n",
    "     output_mipROI_paths,   # Output paths for ROI MIPs\n",
    "     output_maskROI_paths,  # Output paths for ROI masks\n",
    "    ) = load_and_process_czi_singleROI(file_path, file_name, output_path, roi = ROI_num) # Load and process the image (single channel)\n",
    "    # Store all ROI-level outputs for later analysis\n",
    "    all_mipROIs.extend(mip_imageROI)\n",
    "    all_grayROIs.extend(roi_grayROI)\n",
    "    all_claheROIs.extend(roi_claheROI)\n",
    "    all_otsuROIs.extend(roi_otsuROI)\n",
    "    output_ROI_paths.extend(output_mipROI_paths)\n",
    "    output_ROImask_paths.extend(output_maskROI_paths)\n",
    "    all_coords.extend(roi_coords)\n",
    "    if mip_imageROI is None:\n",
    "            continue      # Skip this file if ROI extraction failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15da28f9",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_2_'></a>[Generate ISV segmentation masks](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5645eb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The user is reccommended to clear all jupyter outputs to save memory\n",
    "for i in range(len(all_mipROIs)): # Loop through each ROI to perform vessel segmentation\n",
    "    # Extract sample ID and filename from the ROI output path\n",
    "    sampleID = output_ROI_paths[i].split(\"/\")[-1].split('.tiff')[0]\n",
    "    sample_name = output_ROI_paths[i].split(\"/\")[-1]\n",
    "    # Vessel segmentation within the defined ROI\n",
    "    vessel_seg, remove_list, num_labels = segment_and_analyze_vessels(file_name=sample_name,        # Sample identifier\n",
    "                                                                      image=all_mipROIs[i],         # MIP ROI\n",
    "                                                                      gray_image=all_grayROIs[i],   # Greyscale ROI\n",
    "                                                                      clahe_image=all_claheROIs[i], # CLAHE-enhanced ROI\n",
    "                                                                      otsu_mask=all_otsuROIs[i],    # OTSU threshold ROI\n",
    "                                                                      output_path=output_path,      # Path to output directory\n",
    "                                                                      im_filter=seg_method,         # Vessel segmentation method\n",
    "                                                                      sigma1=sigma1,                # Sigma for enhacement filtering\n",
    "                                                                      hole_size=hole_size,          # Minimum hole size to fill\n",
    "                                                                      ditzle_size=ditzle_size,      # Small object removal threshold\n",
    "                                                                      thresh=thresh)                # Thresholding value\n",
    "    seg_mask.append(vessel_seg)   # Collect all vessel segmentations\n",
    "    ISV_labels.append(num_labels) # Collect the number of ISV per sample\n",
    "    centr = extract_isv_centroids(vessel_seg) # Determine the centroid for each ISV\n",
    "    centroids.append(centr) # Collect all ISV centroids\n",
    "    # Creates a dictionary that collects ISV information\n",
    "    embryo_data.append({\n",
    "            \"sample\": sampleID,     # Sample identifier\n",
    "            \"centroids\": centr,     # ISV centroid coordinates\n",
    "            \"isv_count\": num_labels # Total number of ISV\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60e9271",
   "metadata": {},
   "source": [
    "### <a id='toc3_3_3_'></a>[Calculate probability of ISV loss and save results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017126d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Reference image is selected based on the maximum number of ISV\n",
    "ref_embryo = max(embryo_data, key=lambda e: e[\"isv_count\"]) # Select reference image \n",
    "ref_centroids = ref_embryo[\"centroids\"][:30] # Collect the ISV centroids from the reference image and ensure no more than 30 ISV have been recognised\n",
    "ref_n = len(ref_centroids) # Calculate the number of ISVs used for comparison\n",
    "isv_loss_matrix = []  # Empty matrix that will store probability of ISV loss.\n",
    "# Compare each embryo with the reference and classify groups\n",
    "for e in embryo_data:\n",
    "    lost, _ = detect_lost_isvs(ref_centroids, e[\"centroids\"]) # Compute which ISVs are lost relative to reference embryo\n",
    "    isv_loss_matrix.append(lost.astype(int)) # Append results into a matrix in a binary format (1 = lost, 0 = present)\n",
    "    # Assign group label based on sample name\n",
    "    if ref_name in e['sample']:\n",
    "        e['group'] = 'reference'        # Reference sample\n",
    "    elif target_name in e['sample']:\n",
    "        e['group'] = 'target'           # Target sample\n",
    "    else:\n",
    "        e['group'] = 'Unknown'\n",
    "    e['lost_isvs'] = lost # Store probability of ISV loss\n",
    "isv_loss_matrix = np.array(isv_loss_matrix) # Convert list into array\n",
    "loss_probability = isv_loss_matrix.mean(axis=0) # Calculate the probability of ISV loss across all samples\n",
    "all_loss = np.array([r[\"lost_isvs\"] for r in embryo_data]) # Extract lost ISV arrays for each embryo\n",
    "df_loss = pd.DataFrame(all_loss, columns=[f\"ISV_{i+1}\" for i in range(ref_n)]) # Create DataFrame with one column per ISV\n",
    "# Add metadata columns\n",
    "df_loss.insert(0, \"group\", [r[\"group\"] for r in embryo_data])\n",
    "df_loss.insert(0, \"sample\", [r[\"sample\"] for r in embryo_data])\n",
    "df_loss.insert(0, \"isv_count\", [r[\"isv_count\"] for r in embryo_data])\n",
    "# Sort by group and compute mean probability loss for each ISV\n",
    "prob_summary = (\n",
    "    df_loss.drop(columns=[\"sample\", \"isv_count\"]) # keep only ISV columns and group identifiers\n",
    "        .groupby(\"group\")\n",
    "        .mean() # Mean loss per group\n",
    "        .T      # Transpose so ISVs are rows\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"ISV\"}) # Name ISV column\n",
    "    )\n",
    "plot_loss_probabilities(prob_summary)\n",
    "\n",
    "# Save results as Excel file\n",
    "with pd.ExcelWriter(output_name, engine='openpyxl') as writer:\n",
    "    prob_summary.to_excel(writer, sheet_name=\"Summary\", index=False) # Write first sheet with the summary results\n",
    "    for i, embryo in enumerate(embryo_data): # Write individual embryo data into separate sheets\n",
    "        df = pd.DataFrame({ # Create a dataframe for each embryo\n",
    "            # 'ISV_index': np.arange(1, embryo['isv_count'] + 1),\n",
    "            'Centroid_Y': embryo['centroids'][:, 0], # Store the y coordinate of the ISV centroid\n",
    "            'Centroid_X': embryo['centroids'][:, 1], # Store the x coordinate of the ISV centroid\n",
    "        })\n",
    "        sheet_name = \"_\".join(embryo['sample'].split(\"_\")[0:5]) # Create sheet name with embryo and ISV identifiers\n",
    "        if len(embryo['sample']) < 30: # Use shorter names if sample names are too long\n",
    "            sheet_name = embryo['sample'].split('.')[0][:30]\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False) # Save individual embryo data within the sheet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
